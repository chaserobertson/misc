{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "055217c1",
   "metadata": {},
   "source": [
    "# Compsci 753 Assignment 4\n",
    "## Recommender Systems\n",
    "Latent Factor Modeling with and without bias terms on user-business review data.\n",
    "\n",
    "Chase Robertson\n",
    "\n",
    "UPI: crob873\n",
    "\n",
    "ID: 686249907"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f31dba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(841020, 5) (8582, 5) (8582, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xW294l3Lwh0cxlHU1jwRDA</td>\n",
       "      <td>na4Th5DrNauOv-c43QQFvA</td>\n",
       "      <td>nkN_do3fJ9xekchVC-v68A</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2004-10-19 02:46:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VgBxQqaDgOHq9YRxtMUm3A</td>\n",
       "      <td>6xgcHeLad-VaoTIQewK84A</td>\n",
       "      <td>G5LXEaxhQMF_BVjNHkVr7g</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2005-04-27 23:38:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lgpSS6UsKYIvnQaw8JwHlQ</td>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>G5LXEaxhQMF_BVjNHkVr7g</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2005-04-27 23:38:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xKf_Y6PmebgJtFLULpYCzA</td>\n",
       "      <td>Wxxvi3LZbHNIDwJ-ZimtnA</td>\n",
       "      <td>G5LXEaxhQMF_BVjNHkVr7g</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2005-04-27 23:44:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9P9aP_laBPpHWbdY9ZZYyA</td>\n",
       "      <td>BjH8Xepc10i6OhCDQdX6og</td>\n",
       "      <td>nzsv-p1O8gCfP3XijfQrIw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-04-28 04:42:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id             business_id                 user_id  \\\n",
       "0  xW294l3Lwh0cxlHU1jwRDA  na4Th5DrNauOv-c43QQFvA  nkN_do3fJ9xekchVC-v68A   \n",
       "1  VgBxQqaDgOHq9YRxtMUm3A  6xgcHeLad-VaoTIQewK84A  G5LXEaxhQMF_BVjNHkVr7g   \n",
       "2  lgpSS6UsKYIvnQaw8JwHlQ  --9e1ONYQuAa-CB_Rrw7Tw  G5LXEaxhQMF_BVjNHkVr7g   \n",
       "3  xKf_Y6PmebgJtFLULpYCzA  Wxxvi3LZbHNIDwJ-ZimtnA  G5LXEaxhQMF_BVjNHkVr7g   \n",
       "4  9P9aP_laBPpHWbdY9ZZYyA  BjH8Xepc10i6OhCDQdX6og  nzsv-p1O8gCfP3XijfQrIw   \n",
       "\n",
       "   stars                 date  \n",
       "0    5.0  2004-10-19 02:46:40  \n",
       "1    5.0  2005-04-27 23:38:05  \n",
       "2    5.0  2005-04-27 23:38:49  \n",
       "3    5.0  2005-04-27 23:44:33  \n",
       "4    4.0  2005-04-28 04:42:38  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# create pandas dataframe from specified file which contains\n",
    "# a separate json object on each line for each observation\n",
    "def read_file(filename):\n",
    "    data = {}\n",
    "    file = open(filename, 'r')\n",
    "    for line in file.readlines():\n",
    "        datum = json.loads(line)\n",
    "        for k, v in datum.items():\n",
    "            if k not in data:\n",
    "                data[k] = []\n",
    "            data[k].append(v)\n",
    "    file.close()\n",
    "    return pd.DataFrame(data)\n",
    "    \n",
    "# import each datafile and report shapes and colnames\n",
    "train = read_file('train.json')\n",
    "test = read_file('test.json')\n",
    "val = read_file('val.json')\n",
    "print(train.shape, test.shape, val.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1185507a",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "## Task 1\n",
    "Estimate global bias $b_g$, user specific bias $b_i$, and item specific bias $b_j$ on training data. Report global bias, and user/item specific bias estimates for one example user and business.\n",
    "\n",
    "- First, all unique user and business ID's are collected from all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa65dc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(12345)\n",
    "\n",
    "# Collect all unique user and business ID's\n",
    "user_ids = np.union1d(np.union1d(val['user_id'], test['user_id']), \n",
    "                      train['user_id'])\n",
    "biz_ids = np.union1d(np.union1d(val['business_id'], test['business_id']), \n",
    "                     train['business_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee93291",
   "metadata": {},
   "source": [
    "- Then, global, per-user, and per-business biases are estimated by rating means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d306da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate global, user, and item biases of reviews in dataframe\n",
    "def get_bias(df):\n",
    "    b_g = df['stars'].mean()\n",
    "    \n",
    "    # user and business biases are relative to global bias\n",
    "    b_i = df.groupby('user_id')['stars'].mean() - b_g\n",
    "    b_j = df.groupby('business_id')['stars'].mean() - b_g\n",
    "    \n",
    "    # use dictionaries to speed up lookup\n",
    "    return b_g, b_i.to_dict(), b_j.to_dict()\n",
    "\n",
    "b_g, b_i, b_j = get_bias(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651314de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global bias: 3.83\n",
      "Bias of user \"b4aIMeXOx4cn3bjtdIOo6Q\": -0.46\n",
      "Bias of business \"7VQYoXk3Tc8EZeKuXeixeg\": -0.05\n"
     ]
    }
   ],
   "source": [
    "# display bias estimates: global, specific user and specific business\n",
    "usr = 'b4aIMeXOx4cn3bjtdIOo6Q'\n",
    "biz = '7VQYoXk3Tc8EZeKuXeixeg'\n",
    "\n",
    "print(f'Global bias: {b_g:.2f}')\n",
    "print(f'Bias of user \"{usr}\": {b_i[usr]:.2f}')\n",
    "print(f'Bias of business \"{biz}\": {b_j[biz]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1195d4b",
   "metadata": {},
   "source": [
    "- The user chosen tends to review below the global mean of reviews by half a star. The selected business is quite close to having an average mean review.\n",
    "\n",
    "## Task 2\n",
    "Train a Latent Factor Model without bias, with k=8 factors, for 10 epochs, with learning rate 0.01 and regularisation 0.3, reporting RMSE for each epoch.\n",
    "\n",
    "- User and business k-length factor vectors are initialised from the standard normal distribution.\n",
    "- For each epoch, a rating prediction is calculated with the dot product of each training data point's user and business factor vectors. Squared error is then calcuated and used to update factors by the error gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0058251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use progress bar if verbose training requested\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "train_obs = train.to_numpy()\n",
    "\n",
    "# train Latent Factor Model without bias\n",
    "def train_LFM(data=train_obs, k=8, n_epochs=10, lr=0.01, lmda=0.3, verbose=0):\n",
    "    \n",
    "    # init random factors for each user and business\n",
    "    Q = {u: np.random.standard_normal(k) for u in user_ids}\n",
    "    P = {b: np.random.standard_normal(k) for b in biz_ids}\n",
    "    RMSE = np.zeros(n_epochs)\n",
    "\n",
    "    for e in range(n_epochs):\n",
    "        SE = np.zeros(len(data))\n",
    "        \n",
    "        # for each observation in training data (progress bar if verbose)\n",
    "        t = trange(len(data), leave=False) if verbose else range(len(data))\n",
    "        for i in t:\n",
    "            # get business_id, user_id, and rating of this obs\n",
    "            b, u, r = data[i][1:4]\n",
    "            # compute predicted rating and error\n",
    "            rhat = Q[u].dot(P[b])\n",
    "            err = r - rhat\n",
    "            SE[i] = err**2\n",
    "            # update factors with gradient of error\n",
    "            dLq = -2*err*P[b] + 2*lmda*Q[u]\n",
    "            dLp = -2*err*Q[u] + 2*lmda*P[b]\n",
    "            Q[u] -= lr * dLq\n",
    "            P[b] -= lr * dLp\n",
    "        RMSE[e] = np.sqrt(np.mean(SE))\n",
    "        if verbose:\n",
    "            print(f'Epoch {e} RMSE: {RMSE[e]:.4f}')\n",
    "    return {'k': k, 'RMSE': RMSE, 'Q': Q, 'P': P}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab244753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/841020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 RMSE: 3.3828\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/841020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 RMSE: 1.6362\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/841020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 RMSE: 1.2519\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/841020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 RMSE: 1.1775\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/841020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 RMSE: 1.1530\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/841020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 RMSE: 1.1413\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/841020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 RMSE: 1.1347\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/841020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 RMSE: 1.1303\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/841020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 RMSE: 1.1273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/841020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 RMSE: 1.1252\n"
     ]
    }
   ],
   "source": [
    "lfm8 = train_LFM(k=8, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d7b265",
   "metadata": {},
   "source": [
    "- There is a nicely exponential decline in RMSE over epochs, with 10 actually seeming an ideal stopping point, by chance.\n",
    "\n",
    "## Task 3\n",
    "Report RMSE on validation set of LFM trained with each k in {4,8,16}. Choose the model with best RMSE and report RMSE on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11ceb210",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfm4 = train_LFM(k=4)\n",
    "lfm16 = train_LFM(k=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6071a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no-bias prediction: each prediction is just a dot product of factors\n",
    "def get_predictions(lfm, dataset):\n",
    "    Q = lfm['Q']\n",
    "    P = lfm['P']\n",
    "    data = dataset.to_numpy()\n",
    "    return [Q[x[2]].dot(P[x[1]]) for x in data]\n",
    "\n",
    "def get_rmse(lfm, dataset):\n",
    "    pred = get_predictions(lfm, dataset)\n",
    "    return np.sqrt(np.mean((dataset['stars'] - pred)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71612561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFM k=4 validation RMSE: 1.66596\n",
      "LFM k=8 validation RMSE: 1.69591\n",
      "LFM k=16 validation RMSE: 1.67299\n"
     ]
    }
   ],
   "source": [
    "lfms = [lfm4, lfm8, lfm16]\n",
    "rmses = [get_rmse(lfm, val) for lfm in lfms]\n",
    "\n",
    "for lfm, rmse in zip(lfms, rmses):\n",
    "    print(f'LFM k={lfm[\"k\"]} validation RMSE: {rmse:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "454ce465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LFM (k=4) test RMSE: 1.75655\n"
     ]
    }
   ],
   "source": [
    "best_lfm = lfms[rmses.index(min(rmses))]\n",
    "print(f'Best LFM (k={best_lfm[\"k\"]}) test RMSE: {get_rmse(best_lfm, test):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a74a6a",
   "metadata": {},
   "source": [
    "- The validation performance is quite similar across models. The test RMSE is also not very good - predictions are nearly 2 stars away from their true value.\n",
    "\n",
    "## Task 4\n",
    "Add bias terms to LFM, initialising with the estimated bias from Task 1. Train a model like that in Task 2, reporting RMSE of each epoch and specific bias of a single user and business.\n",
    "\n",
    "- Initial bias estimates, addition of bias to rating prediction calculation, and user/business bias gradient updates are added to the previous LFM training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcb6fcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# Latent Factor Model with bias (starting from initial estimates)\n",
    "def LFM_bias(b_g, b_u, b_b, data=train_obs, k=8, n_epochs=10, lr=0.01, lmda=0.3, verbose=0):\n",
    "    # ensure user and bias estimates are not overwritten across models \n",
    "    b_u = copy.deepcopy(b_u)\n",
    "    b_b = copy.deepcopy(b_b)\n",
    "    Q = {u: np.random.standard_normal(k) for u in user_ids}\n",
    "    P = {b: np.random.standard_normal(k) for b in biz_ids}\n",
    "    RMSE = np.zeros(n_epochs)\n",
    "\n",
    "    for e in range(n_epochs):\n",
    "        SE = np.zeros(len(data))\n",
    "        rng = trange(len(data), leave=False) if verbose else range(len(data))\n",
    "        for i in rng:\n",
    "            b, u, r = data[i][1:4]\n",
    "            # now we include bias estimates in prediction\n",
    "            rhat = b_g + b_u[u] + b_b[b] + Q[u].dot(P[b])\n",
    "            err = r - rhat\n",
    "            SE[i] = err**2\n",
    "            dLq = -2*err*P[b] + 2*lmda*Q[u]\n",
    "            dLp = -2*err*Q[u] + 2*lmda*P[b]\n",
    "            Q[u] -= lr * dLq\n",
    "            P[b] -= lr * dLp\n",
    "            # also update bias estimates by error gradient\n",
    "            b_u[u] -= lr * (-2*err + 2*lmda*b_u[u])\n",
    "            b_b[b] -= lr * (-2*err + 2*lmda*b_b[b])\n",
    "        RMSE[e] = np.sqrt(np.mean(SE))\n",
    "        if verbose:\n",
    "            print(f'Epoch {e} RMSE: {RMSE[e]:.4f}')\n",
    "    return {'k': k, 'RMSE': RMSE, 'Q': Q, 'P': P, 'b_i': b_u, 'b_j': b_b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5f6d220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/841020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 RMSE: 1.5420\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/841020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 RMSE: 1.1150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/841020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 RMSE: 1.0829\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/841020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 RMSE: 1.0720\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/841020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 RMSE: 1.0667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/841020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 RMSE: 1.0635\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/841020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 RMSE: 1.0615\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/841020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 RMSE: 1.0600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/841020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 RMSE: 1.0589\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/841020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 RMSE: 1.0581\n"
     ]
    }
   ],
   "source": [
    "lfm8_b = LFM_bias(b_g, b_i, b_j, k=8, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58076d3",
   "metadata": {},
   "source": [
    "- RMSE started at a much lower value now that bias is included - it seems that starting with reasonable bias estimates makes quite a big impact upfront."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71338e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global bias: 3.83\n",
      "Bias of user \"b4aIMeXOx4cn3bjtdIOo6Q\": -0.30\n",
      "Bias of business \"7VQYoXk3Tc8EZeKuXeixeg\": 0.07\n"
     ]
    }
   ],
   "source": [
    "usr = 'b4aIMeXOx4cn3bjtdIOo6Q'\n",
    "biz = '7VQYoXk3Tc8EZeKuXeixeg'\n",
    "\n",
    "print(f'Global bias: {b_g:.2f}')\n",
    "print(f'Bias of user \"{usr}\": {lfm8_b[\"b_i\"][usr]:.2f}')\n",
    "print(f'Bias of business \"{biz}\": {lfm8_b[\"b_j\"][biz]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9847352c",
   "metadata": {},
   "source": [
    "- The selected user and business bias estimates are not too far off from their naive estimates after training, but have changed somewhat.\n",
    "\n",
    "## Task 5\n",
    "Report RMSE on validation set of LFM trained with bias on each k in {4,8,16}. Choose the model with best RMSE and report RMSE on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74ebf4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfm4_b = LFM_bias(b_g, b_i, b_j, k=4)\n",
    "lfm16_b = LFM_bias(b_g, b_i, b_j, k=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acbaec8",
   "metadata": {},
   "source": [
    "- I've chosen to default to a user/business bias of zero, if the user/business does not already have a bias estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cea31260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFM with bias k=4 validation RMSE: 1.25018\n",
      "LFM with bias k=8 validation RMSE: 1.26316\n",
      "LFM with bias k=16 validation RMSE: 1.28440\n"
     ]
    }
   ],
   "source": [
    "# prediction using LFM with bias\n",
    "def bias_predictions(lfm, dataset):\n",
    "    Q = lfm['Q']\n",
    "    P = lfm['P']\n",
    "    b_u = lfm['b_i']\n",
    "    b_b = lfm['b_j']\n",
    "    data = dataset.to_numpy()\n",
    "    \n",
    "    rhat = [0 for x in data]\n",
    "    for i, x in enumerate(data):\n",
    "        b, u, r = x[1:4]\n",
    "        if u not in b_u:\n",
    "            b_u[u] = 0\n",
    "        if b not in b_b:\n",
    "            b_b[b] = 0\n",
    "        rhat[i] = b_g + b_u[u] + b_b[b] + Q[u].dot(P[b])\n",
    "    return rhat\n",
    "\n",
    "def bias_rmse(lfm, dataset):\n",
    "    pred = bias_predictions(lfm, dataset)\n",
    "    return np.sqrt(np.mean((dataset['stars'] - pred)**2))\n",
    "\n",
    "for lfm in [lfm4_b, lfm8_b, lfm16_b]:\n",
    "    print(f'LFM with bias k={lfm[\"k\"]} validation RMSE: {bias_rmse(lfm, val):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8598e9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LFM with bias (k=4) test RMSE: 1.2335\n"
     ]
    }
   ],
   "source": [
    "print(f'Best LFM with bias (k=4) test RMSE: {bias_rmse(lfm4_b, test):.5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11234ea9",
   "metadata": {},
   "source": [
    "- The test RMSE of the best model with bias terms included is much better than the best without bias from Task 3. Adding bias led to a nearly 50% improvement, an impressive gain in performance for a relatively minor change. The model with k=4 seems best now, though not by much."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
